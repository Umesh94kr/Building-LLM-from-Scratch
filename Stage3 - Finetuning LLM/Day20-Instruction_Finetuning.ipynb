{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCYMiWhDsFmH"
      },
      "source": [
        "## üìò Instruction Fine-Tuning (SFT)\n",
        "\n",
        "Instruction fine-tuning is a training technique where a pretrained Large Language Model (LLM) is further trained on datasets containing **instruction ‚Üí response** pairs.  \n",
        "The goal is to make the model better at following human-written instructions.\n",
        "\n",
        "---\n",
        "\n",
        "#### üîç Why Instruction Fine-Tuning?\n",
        "\n",
        "A pretrained LLM knows language and facts, but it does **not** naturally know how to:\n",
        "- follow instructions precisely  \n",
        "- format answers cleanly  \n",
        "- provide step-by-step reasoning  \n",
        "- produce helpful, safe responses  \n",
        "\n",
        "Instruction fine-tuning aligns the model with *assistant-like behavior*.\n",
        "\n",
        "---\n",
        "\n",
        "#### üß∞ What Data Is Used?\n",
        "\n",
        "Instruction fine-tuning datasets contain pairs like:\n",
        "\n",
        "**Instruction:**  \n",
        "Explain transformers in simple terms.\n",
        "\n",
        "**Response:**  \n",
        "Transformers are neural networks that use attention to understand relationships in text...\n",
        "\n",
        "Popular datasets:\n",
        "- FLAN  \n",
        "- Alpaca / Self-Instruct  \n",
        "- OASST  \n",
        "- Databricks Dolly  \n",
        "- Proprietary human-written datasets\n",
        "\n",
        "---\n",
        "\n",
        "#### üß† What Changes in the Model?\n",
        "\n",
        "During training, the model learns to predict the *correct response tokens* given the instruction.\n",
        "\n",
        "No new layers or heads are added ‚Äî only the weights are updated based on supervised learning.\n",
        "\n",
        "---\n",
        "\n",
        "#### üß™ SFT vs Pretraining vs RLHF\n",
        "\n",
        "| Stage | Description | Purpose |\n",
        "|-------|-------------|---------|\n",
        "| **Pretraining** | Next-token prediction on massive corpora | Learn language + knowledge |\n",
        "| **SFT (Instruction FT)** | Train on instruction‚Äìresponse pairs | Make model follow tasks |\n",
        "| **RLHF** | Reinforcement learning using human preferences | Make model safe and helpful |\n",
        "\n",
        "*Instruction fine-tuning = SFT (Supervised Fine-Tuning)*\n",
        "\n",
        "---\n",
        "\n",
        "#### ‚úîÔ∏è What Does Instruction FT Improve?\n",
        "\n",
        "It enhances:\n",
        "- direct question answering  \n",
        "- reasoning and step-by-step responses  \n",
        "- structured output generation  \n",
        "- translation and summarization  \n",
        "- polite and aligned behavior  \n",
        "- code generation and formatting  \n",
        "\n",
        "---\n",
        "\n",
        "#### üìò Simple Example\n",
        "\n",
        "**Before Instruction FT:**  \n",
        "User: ‚ÄúSummarize this paragraph.‚Äù  \n",
        "Model: Continues writing the paragraph.\n",
        "\n",
        "**After Instruction FT:**  \n",
        "User: ‚ÄúSummarize this paragraph.‚Äù  \n",
        "Model: Provides a concise, structured summary.\n",
        "\n",
        "---\n",
        "\n",
        "#### üìù TL;DR\n",
        "\n",
        "**Instruction fine-tuning teaches an LLM to follow human instructions using supervised datasets of instruction‚Äìresponse pairs.**  \n",
        "It is one of the main steps that turn a raw LLM into a helpful assistant.\n",
        "\n",
        "---\n",
        "\n",
        "## Loading Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qoSmcbRrKqw",
        "outputId": "3444aaf0-337c-4a81-8fa2-2596665d475d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Type of data : <class 'list'>\n",
            "Length of Data : 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('instruction_data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"Data Type of data : {type(data)}\")\n",
        "print(f\"Length of Data : {len(data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEL5WRANsMXm",
        "outputId": "f3f2ad39-697d-417b-e3eb-0acdafe63779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example number 999 : \n",
            " {'instruction': \"What is the plural form of 'child'?\", 'input': '', 'output': \"The plural form of 'child' is 'children'.\"}\n",
            "Example number 300 : \n",
            " {'instruction': 'Correct the verb tense error in the sentence.', 'input': 'She go to school every day.', 'output': \"The corrected sentence should be: 'She goes to school every day.'\"}\n"
          ]
        }
      ],
      "source": [
        "# Lets see some examples\n",
        "print(f\"Example number 999 : \\n {data[998]}\")\n",
        "print(f\"Example number 300 : \\n {data[299]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bs7ijR8lsPP5"
      },
      "outputs": [],
      "source": [
        "# Now we can't just feed these examples directly, we need to combine different components of same example in a single prompt\n",
        "\n",
        "# This Prompt can be of (Alpace Format) or (Phi-3 Format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ViiLkV7ZsVtp"
      },
      "outputs": [],
      "source": [
        "# function to convert intruction-response pairs to a single prompt\n",
        "def make_alpaca_format(data):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{data['instruction']}\"\n",
        "    )\n",
        "    input_text = f\"\\n\\n### Input:\\n{data['input']}\" if data[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XF-J1vkJsYLt"
      },
      "outputs": [],
      "source": [
        "def make_desired_response(data):\n",
        "    desired_response = f\"\\n\\n### Response:\\n{data['output']}\"\n",
        "    return desired_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4_And2ZsaJ_",
        "outputId": "9138b555-a542-4610-f6b3-dcb7a9987a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n"
          ]
        }
      ],
      "source": [
        "print(make_alpaca_format(data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AZsGpYisby7",
        "outputId": "800ace3b-add1-4eb8-d47c-44413e209a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "source": [
        "print(make_desired_response(data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH79CZfXsdVq",
        "outputId": "67c87120-697e-426e-d303-06fc051818f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n",
            "\n",
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "source": [
        "# full alpace format\n",
        "print(make_alpaca_format(data[0]) + make_desired_response(data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4MlzxBtsfLF",
        "outputId": "ae20cb43-54be-45ec-d85f-95babc6b26a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training examples : 935\n",
            "Testing examples : 110\n",
            "Validation examples : 55\n"
          ]
        }
      ],
      "source": [
        "# Splitting Data into train-val-test = 85%, 5%, 10%\n",
        "\n",
        "train_len = int(len(data) * 0.85)\n",
        "test_len = int(len(data) * 0.10)\n",
        "val_len = len(data) - train_len - test_len\n",
        "\n",
        "train_data = data[:train_len]\n",
        "test_data = data[train_len:train_len+test_len]\n",
        "val_data = data[train_len+test_len:]\n",
        "\n",
        "print(f\"Training examples : {train_len}\")\n",
        "print(f\"Testing examples : {test_len}\")\n",
        "print(f\"Validation examples : {val_len}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tb7iLd3EshTN"
      },
      "outputs": [],
      "source": [
        "# Lets make a Dataset class that takes in the data, combines its components to Alpaca format and return tensor of token ids\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.encoded_text = []\n",
        "        for example in data:\n",
        "            alpaca_format = make_alpaca_format(example)\n",
        "            response_format = make_desired_response(example)\n",
        "            tokens_ids = tokenizer.encode(alpaca_format + response_format, allowed_special={\"<|endoftext|>\"})\n",
        "            self.encoded_text.append(tokens_ids)\n",
        "        random.shuffle(self.encoded_text)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_text)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_text[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imPJcdWnsjHC",
        "outputId": "436b2edd-964c-4d26-d299-958d87d3d885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 9487, 1958, 262, 1708, 2456, 416, 511, 14599, 44935, 9376, 25, 1057, 11, 3772, 11, 2952, 198, 198, 21017, 18261, 25, 198, 10987, 25, 49973, 198, 25082, 25, 1215, 752, 425, 198, 21063, 306, 25, 1215, 19011]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "\n",
        "# lets try out any example\n",
        "print(train_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9poiqvu2sodk"
      },
      "source": [
        "#### **Why are we not using DataLoader class to make loaders**\n",
        "- DataLoader expects inputs in all batches to be of same shape\n",
        "- But here all sentences are important, we can't truncate them or pad them for very large number\n",
        "- Here comes collate_functions, which maintains consistent shape of input tensors across one batch\n",
        "\n",
        "- This custom collate function pads the training examples in each batch to have the same length, while allowing different batches to have different lengths. This approach minimizes unnecessary padding by only extending sequences to match the longest one in each batch, not the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NXFcfSzUsmZC"
      },
      "outputs": [],
      "source": [
        "# so this collate function would take examples in batch, pad_them and return a batch tensor\n",
        "\n",
        "def collate_function1(batch, pad_token=50256, device=\"cpu\"):\n",
        "    # find the max length out of the batch\n",
        "    max_len = max(len(token_ids)+1 for token_ids in batch)\n",
        "    input_batch = []\n",
        "    # now we need to add padded tokens\n",
        "    for example in batch:\n",
        "        example += [pad_token]\n",
        "        padded_tokens = [pad_token] * (max_len - len(example))\n",
        "        example += padded_tokens\n",
        "        example = torch.tensor(example[:-1])\n",
        "        input_batch.append(example)\n",
        "\n",
        "    input_batch = torch.vstack(input_batch).to(device)\n",
        "    return input_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3CHRQs1sqUC",
        "outputId": "5dcb6863-59ed-4016-d974-9b5548aa00bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device in use : mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = (\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Device in use : {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrsxngKJssXM",
        "outputId": "3e5ce960-e088-423d-ec02-0fc36bc9645a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collated Batch : \n",
            " tensor([[    1,     2,     3, 50256, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    7,     6,     2,     9,    10],\n",
            "        [    7,     4,     0, 50256, 50256]], device='mps:0')\n"
          ]
        }
      ],
      "source": [
        "batch = [\n",
        "    [1, 2, 3],\n",
        "    [6],\n",
        "    [7, 6, 2, 9, 10],\n",
        "    [7, 4, 0]\n",
        "]\n",
        "\n",
        "collate_batch = collate_function1(batch, device=device)\n",
        "print(f\"Collated Batch : \\n {collate_batch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "izliTO93surB"
      },
      "outputs": [],
      "source": [
        "# we also need to have target batch tensor with input batch tensors\n",
        "\n",
        "def collate_function2(batch, pad_token=50256, device=\"cpu\"):\n",
        "    # find the max length sequence\n",
        "    max_len = max(len(token_ids)+1 for token_ids in batch)\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "\n",
        "    for example in batch:\n",
        "        new_item = example\n",
        "        new_item += [pad_token]\n",
        "        padded_tokens= [pad_token] * (max_len - len(new_item))\n",
        "        new_item += padded_tokens\n",
        "        input_ids = torch.tensor(new_item[:-1])\n",
        "        target_ids = torch.tensor(new_item[1:])\n",
        "        input_batch.append(input_ids)\n",
        "        target_batch.append(target_ids)\n",
        "\n",
        "    input_batch = torch.vstack(input_batch).to(device)\n",
        "    target_batch = torch.vstack(target_batch).to(device)\n",
        "\n",
        "    return input_batch, target_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il_V3Sn7sxES",
        "outputId": "a7f87a3d-5715-476d-8a17-c5378ebb006a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collated input batch : \n",
            " tensor([[    1,     2,     3, 50256, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    7,     6,     2,     9,    10],\n",
            "        [    7,     4,     0, 50256, 50256]])\n",
            "Collated target batch : \n",
            " tensor([[    2,     3, 50256, 50256, 50256],\n",
            "        [50256, 50256, 50256, 50256, 50256],\n",
            "        [    6,     2,     9,    10, 50256],\n",
            "        [    4,     0, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "batch = [\n",
        "    [1, 2, 3],\n",
        "    [6],\n",
        "    [7, 6, 2, 9, 10],\n",
        "    [7, 4, 0]\n",
        "]\n",
        "\n",
        "collated_input_batch, collated_target_batch = collate_function2(batch)\n",
        "print(f\"Collated input batch : \\n {collated_input_batch}\")\n",
        "print(f\"Collated target batch : \\n {collated_target_batch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LFoXyLCwsyz_"
      },
      "outputs": [],
      "source": [
        "# this is upgraded collate function which will replace padded tokens with id = -100\n",
        "# this helps to exclude irrelevant tokens while calculating loss\n",
        "\n",
        "# we also need to have target batch tensor with input batch tensors\n",
        "\n",
        "def collate_function3(batch, pad_token=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
        "    # find the max length sequence\n",
        "    max_len = max(len(token_ids)+1 for token_ids in batch)\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "\n",
        "    for example in batch:\n",
        "        new_item = example\n",
        "        new_item += [pad_token]\n",
        "        padded_tokens= [pad_token] * (max_len - len(new_item))\n",
        "        new_item += padded_tokens\n",
        "        input_ids = torch.tensor(new_item[:-1])\n",
        "        target_ids = torch.tensor(new_item[1:])\n",
        "\n",
        "        # create a mask\n",
        "        mask = target_ids == pad_token\n",
        "        # [0, 0, 0, 1, 1]\n",
        "        indices = torch.nonzero(mask)\n",
        "        # [3, 4]\n",
        "        # indices.numel() tells about number of elements in a tensor\n",
        "        if indices.numel() > 1:\n",
        "            # replace all padded tokens with -100 except one just after ending of sentence\n",
        "            # it doesn't consider that time step for calculating loss\n",
        "            target_ids[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = input_ids[:allowed_max_length]\n",
        "            targets = target_ids[:allowed_max_length]\n",
        "\n",
        "        input_batch.append(input_ids)\n",
        "        target_batch.append(target_ids)\n",
        "\n",
        "    input_batch = torch.vstack(input_batch).to(device)\n",
        "    target_batch = torch.vstack(target_batch).to(device)\n",
        "\n",
        "    return input_batch, target_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPo7GB43s1OT",
        "outputId": "dd6ff3b3-d59d-425f-8c90-63b391da41d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collated input batch : \n",
            " tensor([[    1,     2,     3, 50256, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    7,     6,     2,     9,    10],\n",
            "        [    7,     4,     0, 50256, 50256]])\n",
            "Collated target batch : \n",
            " tensor([[    2,     3, 50256,  -100,  -100],\n",
            "        [50256,  -100,  -100,  -100,  -100],\n",
            "        [    6,     2,     9,    10, 50256],\n",
            "        [    4,     0, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "batch = [\n",
        "    [1, 2, 3],\n",
        "    [6],\n",
        "    [7, 6, 2, 9, 10],\n",
        "    [7, 4, 0]\n",
        "]\n",
        "\n",
        "collated_input_batch, collated_target_batch = collate_function3(batch)\n",
        "print(f\"Collated input batch : \\n {collated_input_batch}\")\n",
        "print(f\"Collated target batch : \\n {collated_target_batch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHjAgrE2s6G-"
      },
      "source": [
        "#### **DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BAI1aV1Ks2tH"
      },
      "outputs": [],
      "source": [
        "# this is custom DataLoader\n",
        "class CustomDataLoader:\n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        idx = 0\n",
        "        self.X = []\n",
        "        self.y = []\n",
        "\n",
        "        while(idx != len(dataset)):\n",
        "            if idx+batch_size >= len(dataset):\n",
        "                break\n",
        "            batch1 = dataset[:batch_size]\n",
        "            input_ids, target_ids = collate_function3(batch1)\n",
        "            idx += batch_size\n",
        "            self.X.append(input_ids)\n",
        "            self.y.append(target_ids)\n",
        "\n",
        "    def get_loader(self):\n",
        "        return self.X, self.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n5BaiXOJs70_"
      },
      "outputs": [],
      "source": [
        "# instead of our custom DataLoader we can also use PyTorch DataLoader, but need to define the collate function for that\n",
        "# PyTorch DataLoader expects a function that takes batch only something like : collate_function(batch)\n",
        "\n",
        "# for this purpose to prefill other arguements like device and max_length - we'll use patial function from functools\n",
        "\n",
        "from functools import partial\n",
        "customized_collate_fn = partial(collate_function3, device=device, allowed_max_length=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOhgZRX2s_iH"
      },
      "source": [
        "#### **PyTorch DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6imufBHNs9ly"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=customized_collate_fn, shuffle=True, drop_last=True, num_workers=num_workers)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=customized_collate_fn, shuffle=False, drop_last=False, num_workers=num_workers)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,collate_fn=customized_collate_fn, shuffle=False, drop_last=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVV-OSj7tBK8",
        "outputId": "bf6e5442-97e5-40e7-b1a1-0f5f66976070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of elements in batch1 : 2\n",
            "Train loader:\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n"
          ]
        }
      ],
      "source": [
        "batch1 = next(iter(train_loader))\n",
        "print(f\"Number of elements in batch1 : {len(batch1)}\")\n",
        "\n",
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cdhUJW_tHQ4"
      },
      "source": [
        "#### **Loading Pre-trained LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2iK-lPjtE9n",
        "outputId": "598663e3-a2e6-48be-f66b-316b64f3c889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text : Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = make_alpaca_format(val_data[0])\n",
        "print(f\"Input text : {input_text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FdTUXQoqtJZn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YFku0ofPtLOw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YQu-3D0ttNPt"
      },
      "outputs": [],
      "source": [
        "from gpt_download3 import download_and_load_gpt2\n",
        "from GPT2_architecture import GPTModel\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRXELJSNtPMP"
      },
      "outputs": [],
      "source": [
        "# Downloading model\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2_medium\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Ta-ZW0sdtwSe"
      },
      "outputs": [],
      "source": [
        "# after loading your model\n",
        "from gpt_download3 import load_params\n",
        "settings, params = load_params('gpt2_medium/355M')\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpIbDVYVtxru",
        "outputId": "cb20b040-7a94-4916-dedd-81a3d0d264dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1024)\n",
              "  (pos_emb): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## a function to generate output token ids\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "-b0EBSZeuC67"
      },
      "outputs": [],
      "source": [
        "# funtion to convet input text to token ids\n",
        "def text_to_token_ids(input_text):\n",
        "    tokenizer = tiktoken.get_encoding('gpt2')\n",
        "    tokens = tokenizer.encode(input_text, allowed_special={'<|endoftext|>'})\n",
        "    return tokens\n",
        "\n",
        "def token_ids_to_text(input_ids):\n",
        "    tokenizer = tiktoken.get_encoding('gpt2')\n",
        "    text = tokenizer.decode(input_ids)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JE1_cHBZuEiU",
        "outputId": "b2edd019-8420-4b53-82a9-baee4241aca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'#Y($Qz8'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token = [2, 56, 7, 3, 48, 89, 23]\n",
        "token_ids_to_text(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "trc5idzfuGWM"
      },
      "outputs": [],
      "source": [
        "def generate(model, input_text, max_new_tokens=35,\n",
        "             context_size=BASE_CONFIG['context_length'],\n",
        "             eos=50256, device='cpu'):\n",
        "    \n",
        "    input_ids = text_to_token_ids(input_text)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        context = input_ids[-context_size:]\n",
        "        inputs = torch.tensor(context, device=device).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(inputs)[:, -1, :]\n",
        "            next_id = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "        if next_id == eos:\n",
        "            input_ids.append(eos)\n",
        "            break\n",
        "\n",
        "        input_ids.append(next_id)\n",
        "\n",
        "    # ---- cut at EOS ----\n",
        "    if eos in input_ids:\n",
        "        input_ids = input_ids[:input_ids.index(eos)]\n",
        "    print(f\"Input ids : {input_ids}\")\n",
        "\n",
        "    return token_ids_to_text(input_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdjpzeVmuICC",
        "outputId": "f972a2a3-c660-41da-fdb4-bc867b7f349f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = make_alpaca_format(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LZ7nS7euJv3",
        "outputId": "a08f1d17-c14f-4be3-b902-f4ca9ab61519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input ids : [21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 3103, 1851, 262, 4075, 6827, 284, 14513, 25, 705, 464, 21221, 38383, 262, 9799, 790, 1110, 2637, 198, 198, 21017, 18261, 25, 198, 464, 9799, 373, 5597, 416, 262, 21221, 13, 50256, 198, 50256, 198, 21017, 18261, 25, 198, 464, 21221, 5597, 262, 9799, 13, 50256, 198, 50256, 50256, 50256, 50256, 198]\n",
            "\n",
            "\n",
            "### Response:\n",
            "The meal was prepared by the chef.<|endoftext|>\n",
            "<|endoftext|>\n",
            "### Response:\n",
            "The chef prepared the meal.<|endoftext|>\n",
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generated_text = generate(model, input_text=input_text)\n",
        "\n",
        "print(generated_text[len(input_text):])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7T6U1tRVuLS3"
      },
      "outputs": [],
      "source": [
        "## function to calculate batch loss\n",
        "def calculate_batch_loss(model, input_batch, target_batch, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_batch)\n",
        "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten(0))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qdP0xj_YuNP2"
      },
      "outputs": [],
      "source": [
        "## function that can calculate loss of a dataloader\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calc_loss_loader(model, data_loader, device):\n",
        "    total_loss = 0\n",
        "    for X, y in tqdm(data_loader):\n",
        "        loss = calculate_batch_loss(model, X, y, device)\n",
        "        total_loss += loss.item()\n",
        "    total_loss /= len(data_loader)\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCgM7vZ0uN99",
        "outputId": "00ef0fba-d558-4d3d-c2d9-6aab14d14e41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  6.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss of val data before training : 3.816929919379098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# lets calculate loss before training\n",
        "val_data_loss = calc_loss_loader(model, val_loader, device)\n",
        "\n",
        "print(f\"Loss of val data before training : {val_data_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h1yRoJQcua4g"
      },
      "outputs": [],
      "source": [
        "# Training configs\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SInibfnCu45W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('./instruction_checkpoints', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "eFWIVt4Cucnu",
        "outputId": "efc74be2-2cd0-49d1-8ef6-9def66d59412"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [45:15<00:00, 543.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/5 | Train : 0.2043 | Val : 1.0965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    model.train()\n",
        "    batch_train_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X)\n",
        "        loss = torch.nn.functional.cross_entropy(preds.flatten(0, 1), y.flatten(0))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        batch_train_loss += loss.item()\n",
        "\n",
        "    batch_train_loss /= len(train_loader)\n",
        "    train_loss.append(batch_train_loss)\n",
        "\n",
        "    # calculating val loss\n",
        "    with torch.no_grad():\n",
        "      batch_val_loss = 0\n",
        "      for X, y in val_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        logits = model(X)\n",
        "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), y.flatten(0))\n",
        "        batch_val_loss += loss.item()\n",
        "    batch_val_loss /= len(val_loader)\n",
        "    val_loss.append(batch_val_loss)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(train_loss, label='Train Loss', marker='o')\n",
        "    plt.plot(val_loss, label='Validation Loss', marker='s')\n",
        "    plt.title('Training Progress')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    torch.save(model.state_dict(), './instruction_checkpoints/instruction_finetuned_gpt_model.pth')\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train : {train_loss[-1]:.4f} | Val : {val_loss[-1]:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Make Inference from Pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "\n",
        "state_dict = torch.load(\"instruction_checkpoints/instruction_finetuned_gpt_model.pth\", map_location='cpu')\n",
        "\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n"
          ]
        }
      ],
      "source": [
        "# making inference \n",
        "example = make_alpaca_format(test_data[0])\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input ids : [21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 30003, 6525, 262, 6827, 1262, 257, 985, 576, 13, 198, 198, 21017, 23412, 25, 198, 464, 1097, 318, 845, 3049, 13, 198, 198, 21017, 18261, 25, 198, 464, 1097, 318, 355, 3049, 355, 257, 1125, 316, 993, 13]\n",
            "Actual output : The car is as fast as lightning.\n",
            "Generated output : \n",
            "\n",
            "### Response:\n",
            "The car is as fast as a cheetah.\n"
          ]
        }
      ],
      "source": [
        "generated_output = generate(model, example)\n",
        "print(f\"Actual output : {test_data[0]['output']}\")\n",
        "print(f'Generated output : {generated_output[len(example):]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The car is as fast as a cheetah.<|endoftext|>\\n<|endoftext|>\\nThe car is as a cheetah.<|endoftext|>'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_output[len(example):].replace(\"### Response:\", \"\").strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **See now model is able to follow instructions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Next Goal is to make an evaluation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
