{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f71e54d",
   "metadata": {},
   "source": [
    "## üìò Instruction Fine-Tuning (SFT)\n",
    "\n",
    "Instruction fine-tuning is a training technique where a pretrained Large Language Model (LLM) is further trained on datasets containing **instruction ‚Üí response** pairs.  \n",
    "The goal is to make the model better at following human-written instructions.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîç Why Instruction Fine-Tuning?\n",
    "\n",
    "A pretrained LLM knows language and facts, but it does **not** naturally know how to:\n",
    "- follow instructions precisely  \n",
    "- format answers cleanly  \n",
    "- provide step-by-step reasoning  \n",
    "- produce helpful, safe responses  \n",
    "\n",
    "Instruction fine-tuning aligns the model with *assistant-like behavior*.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß∞ What Data Is Used?\n",
    "\n",
    "Instruction fine-tuning datasets contain pairs like:\n",
    "\n",
    "**Instruction:**  \n",
    "Explain transformers in simple terms.\n",
    "\n",
    "**Response:**  \n",
    "Transformers are neural networks that use attention to understand relationships in text...\n",
    "\n",
    "Popular datasets:\n",
    "- FLAN  \n",
    "- Alpaca / Self-Instruct  \n",
    "- OASST  \n",
    "- Databricks Dolly  \n",
    "- Proprietary human-written datasets\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† What Changes in the Model?\n",
    "\n",
    "During training, the model learns to predict the *correct response tokens* given the instruction.\n",
    "\n",
    "No new layers or heads are added ‚Äî only the weights are updated based on supervised learning.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß™ SFT vs Pretraining vs RLHF\n",
    "\n",
    "| Stage | Description | Purpose |\n",
    "|-------|-------------|---------|\n",
    "| **Pretraining** | Next-token prediction on massive corpora | Learn language + knowledge |\n",
    "| **SFT (Instruction FT)** | Train on instruction‚Äìresponse pairs | Make model follow tasks |\n",
    "| **RLHF** | Reinforcement learning using human preferences | Make model safe and helpful |\n",
    "\n",
    "*Instruction fine-tuning = SFT (Supervised Fine-Tuning)*\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úîÔ∏è What Does Instruction FT Improve?\n",
    "\n",
    "It enhances:\n",
    "- direct question answering  \n",
    "- reasoning and step-by-step responses  \n",
    "- structured output generation  \n",
    "- translation and summarization  \n",
    "- polite and aligned behavior  \n",
    "- code generation and formatting  \n",
    "\n",
    "---\n",
    "\n",
    "#### üìò Simple Example\n",
    "\n",
    "**Before Instruction FT:**  \n",
    "User: ‚ÄúSummarize this paragraph.‚Äù  \n",
    "Model: Continues writing the paragraph.\n",
    "\n",
    "**After Instruction FT:**  \n",
    "User: ‚ÄúSummarize this paragraph.‚Äù  \n",
    "Model: Provides a concise, structured summary.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìù TL;DR\n",
    "\n",
    "**Instruction fine-tuning teaches an LLM to follow human instructions using supervised datasets of instruction‚Äìresponse pairs.**  \n",
    "It is one of the main steps that turn a raw LLM into a helpful assistant.\n",
    "\n",
    "---\n",
    "\n",
    "## Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc0309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of data : <class 'list'>\n",
      "Length of Data : 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('instruction_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Data Type of data : {type(data)}\")\n",
    "print(f\"Length of Data : {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10729b2",
   "metadata": {},
   "source": [
    "`We have 1100 instruction-response pairs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7a8179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example number 999 : \n",
      " {'instruction': \"What is the plural form of 'child'?\", 'input': '', 'output': \"The plural form of 'child' is 'children'.\"}\n",
      "Example number 300 : \n",
      " {'instruction': 'Correct the verb tense error in the sentence.', 'input': 'She go to school every day.', 'output': \"The corrected sentence should be: 'She goes to school every day.'\"}\n"
     ]
    }
   ],
   "source": [
    "# Lets see some examples \n",
    "print(f\"Example number 999 : \\n {data[998]}\")\n",
    "print(f\"Example number 300 : \\n {data[299]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6108ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can't just feed these examples directly, we need to combine different components of same example in a single prompt \n",
    "\n",
    "# This Prompt can be of (Alpace Format) or (Phi-3 Format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e65d7",
   "metadata": {},
   "source": [
    "##### **Alpaca Format**\n",
    "\n",
    "<img src=\"Screenshot 2025-11-21 at 1.15.45‚ÄØAM.png\" width=\"500\" height=\"300\">\n",
    "\n",
    "##### **Phi-3 Format**\n",
    "\n",
    "<img src=\"Screenshot 2025-11-21 at 1.19.18‚ÄØAM.png\" width=\"500\" height=\"200\">\n",
    "\n",
    "---\n",
    "\n",
    "For this project we'll stick with Stanford Alpace format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d796baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert intruction-response pairs to a single prompt \n",
    "def make_alpaca_format(data):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{data['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{data['input']}\" if data[\"input\"] else \"\"\n",
    "    \n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28f229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_desired_response(data):\n",
    "    desired_response = f\"\\n\\n### Response:\\n{data['output']}\"\n",
    "    return desired_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a01d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n"
     ]
    }
   ],
   "source": [
    "print(make_alpaca_format(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17f4cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "print(make_desired_response(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e52b47a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "# full alpace format\n",
    "print(make_alpaca_format(data[0]) + make_desired_response(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3b6063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples : 935\n",
      "Testing examples : 110\n",
      "Validation examples : 55\n"
     ]
    }
   ],
   "source": [
    "# Splitting Data into train-val-test = 85%, 5%, 10%\n",
    "\n",
    "train_len = int(len(data) * 0.85)\n",
    "test_len = int(len(data) * 0.10)\n",
    "val_len = len(data) - train_len - test_len\n",
    "\n",
    "train_data = data[:train_len]\n",
    "test_data = data[train_len:train_len+test_len]\n",
    "val_data = data[train_len+test_len:]\n",
    "\n",
    "print(f\"Training examples : {train_len}\")\n",
    "print(f\"Testing examples : {test_len}\")\n",
    "print(f\"Validation examples : {val_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32321cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a Dataset class that takes in the data, combines its components to Alpaca format and return tensor of token ids\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.encoded_text = []\n",
    "        for example in data:\n",
    "            alpaca_format = make_alpaca_format(example)\n",
    "            response_format = make_desired_response(example)\n",
    "            tokens_ids = tokenizer.encode(alpaca_format + response_format, allowed_special={\"<|endoftext|>\"})\n",
    "            self.encoded_text.append(tokens_ids)\n",
    "        random.shuffle(self.encoded_text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_text)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_text[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a40ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 2061, 318, 262, 5931, 10451, 329, 6588, 17556, 30, 198, 198, 21017, 18261, 25, 198, 464, 5931, 10451, 329, 6588, 17556, 318, 7375, 17, 13]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "\n",
    "# lets try out any example \n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab1c4f",
   "metadata": {},
   "source": [
    "#### **Why are we not using DataLoader class to make loaders**\n",
    "- DataLoader expects inputs in all batches to be of same shape\n",
    "- But here all sentences are important, we can't truncate them or pad them for very large number\n",
    "- Here comes collate_functions, which maintains consistent shape of input tensors across one batch\n",
    "\n",
    "- This custom collate function pads the training examples in each batch to have the same length, while allowing different batches to have different lengths. This approach minimizes unnecessary padding by only extending sequences to match the longest one in each batch, not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31b9c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so this collate function would take examples in batch, pad_them and return a batch tensor\n",
    "\n",
    "def collate_function1(batch, pad_token=50256, device=\"cpu\"):\n",
    "    # find the max length out of the batch \n",
    "    max_len = max(len(token_ids)+1 for token_ids in batch) \n",
    "    input_batch = []\n",
    "    # now we need to add padded tokens\n",
    "    for example in batch:\n",
    "        example += [pad_token]\n",
    "        padded_tokens = [pad_token] * (max_len - len(example))\n",
    "        example += padded_tokens\n",
    "        example = torch.tensor(example[:-1])\n",
    "        input_batch.append(example)\n",
    "\n",
    "    input_batch = torch.vstack(input_batch).to(device)\n",
    "    return input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "354c3e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use : mps\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() \n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Device in use : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c985018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collated Batch : \n",
      " tensor([[    1,     2,     3, 50256, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    7,     6,     2,     9,    10],\n",
      "        [    7,     4,     0, 50256, 50256]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "batch = [\n",
    "    [1, 2, 3],\n",
    "    [6],\n",
    "    [7, 6, 2, 9, 10],\n",
    "    [7, 4, 0]\n",
    "]\n",
    "\n",
    "collate_batch = collate_function1(batch, device=device)\n",
    "print(f\"Collated Batch : \\n {collate_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7fe045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to have target batch tensor with input batch tensors\n",
    "\n",
    "def collate_function2(batch, pad_token=50256, device=\"cpu\"):\n",
    "    # find the max length sequence\n",
    "    max_len = max(len(token_ids)+1 for token_ids in batch)\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for example in batch:\n",
    "        new_item = example\n",
    "        new_item += [pad_token]\n",
    "        padded_tokens= [pad_token] * (max_len - len(new_item))\n",
    "        new_item += padded_tokens\n",
    "        input_ids = torch.tensor(new_item[:-1])\n",
    "        target_ids = torch.tensor(new_item[1:])\n",
    "        input_batch.append(input_ids)\n",
    "        target_batch.append(target_ids)\n",
    "\n",
    "    input_batch = torch.vstack(input_batch).to(device)\n",
    "    target_batch = torch.vstack(target_batch).to(device)\n",
    "\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92e59c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collated input batch : \n",
      " tensor([[    1,     2,     3, 50256, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    7,     6,     2,     9,    10],\n",
      "        [    7,     4,     0, 50256, 50256]])\n",
      "Collated target batch : \n",
      " tensor([[    2,     3, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256],\n",
      "        [    6,     2,     9,    10, 50256],\n",
      "        [    4,     0, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "batch = [\n",
    "    [1, 2, 3],\n",
    "    [6],\n",
    "    [7, 6, 2, 9, 10],\n",
    "    [7, 4, 0]\n",
    "]\n",
    "\n",
    "collated_input_batch, collated_target_batch = collate_function2(batch)\n",
    "print(f\"Collated input batch : \\n {collated_input_batch}\")\n",
    "print(f\"Collated target batch : \\n {collated_target_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55258b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is upgraded collate function which will replace padded tokens with id = -100 \n",
    "# this helps to exclude irrelevant tokens while calculating loss\n",
    "\n",
    "# we also need to have target batch tensor with input batch tensors\n",
    "\n",
    "def collate_function3(batch, pad_token=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    # find the max length sequence\n",
    "    max_len = max(len(token_ids)+1 for token_ids in batch)\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for example in batch:\n",
    "        new_item = example\n",
    "        new_item += [pad_token]\n",
    "        padded_tokens= [pad_token] * (max_len - len(new_item))\n",
    "        new_item += padded_tokens\n",
    "        input_ids = torch.tensor(new_item[:-1])\n",
    "        target_ids = torch.tensor(new_item[1:])\n",
    "\n",
    "        # create a mask \n",
    "        mask = target_ids == pad_token\n",
    "        # [0, 0, 0, 1, 1]\n",
    "        indices = torch.nonzero(mask)\n",
    "        # [3, 4]\n",
    "        # indices.numel() tells about number of elements in a tensor \n",
    "        if indices.numel() > 1:\n",
    "            # replace all padded tokens with -100 except one just after ending of sentence\n",
    "            # it doesn't consider that time step for calculating loss\n",
    "            target_ids[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = input_ids[:allowed_max_length]\n",
    "            targets = target_ids[:allowed_max_length]\n",
    "\n",
    "        input_batch.append(input_ids)\n",
    "        target_batch.append(target_ids)\n",
    "\n",
    "    input_batch = torch.vstack(input_batch).to(device)\n",
    "    target_batch = torch.vstack(target_batch).to(device)\n",
    "\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "255b75aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collated input batch : \n",
      " tensor([[    1,     2,     3, 50256, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    7,     6,     2,     9,    10],\n",
      "        [    7,     4,     0, 50256, 50256]])\n",
      "Collated target batch : \n",
      " tensor([[    2,     3, 50256,  -100,  -100],\n",
      "        [50256,  -100,  -100,  -100,  -100],\n",
      "        [    6,     2,     9,    10, 50256],\n",
      "        [    4,     0, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "batch = [\n",
    "    [1, 2, 3],\n",
    "    [6],\n",
    "    [7, 6, 2, 9, 10],\n",
    "    [7, 4, 0]\n",
    "]\n",
    "\n",
    "collated_input_batch, collated_target_batch = collate_function3(batch)\n",
    "print(f\"Collated input batch : \\n {collated_input_batch}\")\n",
    "print(f\"Collated target batch : \\n {collated_target_batch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe43755",
   "metadata": {},
   "source": [
    "#### **DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c24e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is custom DataLoader \n",
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        idx = 0\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        while(idx != len(dataset)):\n",
    "            if idx+batch_size >= len(dataset):\n",
    "                break\n",
    "            batch1 = dataset[:batch_size]\n",
    "            input_ids, target_ids = collate_function3(batch1)\n",
    "            idx += batch_size\n",
    "            self.X.append(input_ids) \n",
    "            self.y.append(target_ids)\n",
    "        \n",
    "    def get_loader(self):\n",
    "        return self.X, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23da1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of our custom DataLoader we can also use PyTorch DataLoader, but need to define the collate function for that\n",
    "# PyTorch DataLoader expects a function that takes batch only something like : collate_function(batch)\n",
    "\n",
    "# for this purpose to prefill other arguements like device and max_length - we'll use patial function from functools\n",
    "\n",
    "from functools import partial\n",
    "customized_collate_fn = partial(collate_function3, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b290431",
   "metadata": {},
   "source": [
    "#### **PyTorch DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c7b50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8 \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=customized_collate_fn, shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=customized_collate_fn, shuffle=False, drop_last=False, num_workers=num_workers)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,collate_fn=customized_collate_fn, shuffle=False, drop_last=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b5ad229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in batch1 : 2\n",
      "Train loader:\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n"
     ]
    }
   ],
   "source": [
    "batch1 = next(iter(train_loader))\n",
    "print(f\"Number of elements in batch1 : {len(batch1)}\")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febc438",
   "metadata": {},
   "source": [
    "#### **Loading Pre-trained LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab332a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text : Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = make_alpaca_format(val_data[0])\n",
    "print(f\"Input text : {input_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb04935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5782cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a515d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download3 import download_and_load_gpt2\n",
    "from GPT2_architecture import GPTModel\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f3e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umesh/Desktop/LLM from Scratch/myenv/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77.0/77.0 [00:00<00:00, 39.9kiB/s]\n",
      "encoder.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.04M/1.04M [00:06<00:00, 154kiB/s] \n",
      "hparams.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.0/91.0 [00:00<00:00, 71.0kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [1:35:19<00:00, 248kiB/s]   \n",
      "model.ckpt.index: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.4k/10.4k [00:00<00:00, 9.10MiB/s]\n",
      "model.ckpt.meta: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 927k/927k [00:02<00:00, 386kiB/s]  \n",
      "vocab.bpe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:01<00:00, 330kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2_medium\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7e9b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after loading your model  \n",
    "from gpt_download3 import load_params\n",
    "settings, params = load_params('gpt2_medium/355M')\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "beb9db0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a function to generate output token ids \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13abfd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to convet input text to token ids \n",
    "def text_to_token_ids(input_text):\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    tokens = tokenizer.encode(input_text)\n",
    "    return tokens\n",
    "\n",
    "def token_ids_to_text(input_ids):\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    text = tokenizer.decode(input_ids)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f320c9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Y($Qz8'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = [2, 56, 7, 3, 48, 89, 23]\n",
    "token_ids_to_text(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ace321ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output \n",
    "def generate(model, input_text, max_new_tokens=35, context_size=BASE_CONFIG['context_length'], eos=50526):\n",
    "    # convert input text to token ids \n",
    "    input_ids = text_to_token_ids(input_text)\n",
    "    for i in range(max_new_tokens):\n",
    "        if len(input_ids) > context_size:\n",
    "            inputs = input_ids[-context_size:]\n",
    "        else:\n",
    "            inputs = input_ids\n",
    "        inputs = torch.tensor(inputs)\n",
    "        inputs = inputs.unsqueeze(0) # giving batch dimension\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            # take the last token from output \n",
    "            output_logit = outputs[:, -1, :]\n",
    "            # now use the softmax and find the argmax\n",
    "            output_token = (torch.argmax(output_logit, dim=-1)).squeeze(0)\n",
    "\n",
    "            input_ids += [output_token.item()]\n",
    "    \n",
    "    return token_ids_to_text(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84b4d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = make_alpaca_format(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ef973c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate(model, input_text=input_text)\n",
    "\n",
    "print(generated_text[len(input_text):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "718e87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to calculate batch loss \n",
    "def calculate_batch_loss(model, input_batch, target_batch, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten(0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c23b0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that can calculate loss of a dataloader \n",
    "from tqdm import tqdm\n",
    "\n",
    "def calc_loss_loader(model, data_loader, device):\n",
    "    total_loss = 0\n",
    "    for X, y in tqdm(data_loader):\n",
    "        loss = calculate_batch_loss(model, X, y, device)\n",
    "        total_loss += loss.item()\n",
    "    total_loss /= len(data_loader)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0f917dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d308aac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [06:18<00:00, 54.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of val data before training : 3.809184891836984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lets calculate loss before training \n",
    "val_data_loss = calc_loss_loader(model, val_loader, device)\n",
    "\n",
    "print(f\"Loss of val data before training : {val_data_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac627a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configs\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "epochs = 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
