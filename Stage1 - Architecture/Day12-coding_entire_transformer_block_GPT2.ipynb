{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2468ff5b",
   "metadata": {},
   "source": [
    "#### **Tranaformer Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5eeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (where 'transformer_components' folder lives)\n",
    "sys.path.append(\"/Users/umesh/Desktop/LLM from Scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a4c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_components.multihead_attention import MultiheadAttention\n",
    "from transformer_components.positional_encodings import PositionalEncoding\n",
    "from transformer_components.embeddings import GetEmbeddings\n",
    "from transformer_components.feed_forward import FeedForward\n",
    "from transformer_components.activation import GeLU\n",
    "from transformer_components.layer_norm import LayerNorm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4710de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias (W*x + b)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d32eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa563b2c",
   "metadata": {},
   "source": [
    "#### **Multihead Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1af0fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.n_heads = configs['n_heads']\n",
    "        self.head_dim = int(configs['emb_dim'] / configs['n_heads'])\n",
    "        self.Wq = nn.Linear(configs['emb_dim'], configs['emb_dim'])\n",
    "        self.Wk = nn.Linear(configs['emb_dim'], configs['emb_dim'])\n",
    "        self.Wv = nn.Linear(configs['emb_dim'], configs['emb_dim'])\n",
    "        self.proj = nn.Linear(configs['emb_dim'], configs['emb_dim'])\n",
    "        self.register_buffer( 'mask',torch.triu(torch.ones(configs['context_length'], configs['context_length']), diagonal=1))\n",
    "        self.dropout = torch.nn.Dropout(configs['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape of x (B, T (context_len), D) \n",
    "        B, T, D = x.shape\n",
    "        query = self.Wq(x)    # (B, T, D)\n",
    "        key = self.Wk(x)\n",
    "        value = self.Wv(x)\n",
    "\n",
    "        # unrolling these weight Q/K/V metrices from (B, T, D) -> (B, T, n_heads, head_dim)\n",
    "        query = query.view(B, T, self.n_heads, self.head_dim)\n",
    "        key = key.view(B, T, self.n_heads, self.head_dim)\n",
    "        value = value.view(B, T, self.n_heads, self.head_dim)\n",
    "\n",
    "        # transpose (batch, context_len, n_heads, head_dim) -> (batch, n_heads, context_len, head_dim)\n",
    "        keys = key.transpose(1, 2)\n",
    "        queries = query.transpose(1, 2)\n",
    "        values = value.transpose(1, 2)\n",
    "\n",
    "        # time to calculate attention weights of shape (B, n_heads, context_len, context_len)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        attn_scores = attn_scores.masked_fill_(self.mask.bool()[:T, :T], -torch.inf)\n",
    "        attn_scores = attn_scores / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "        scaled_attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        scaled_attn_weights = self.dropout(scaled_attn_weights)\n",
    "        outputs = scaled_attn_weights @ values\n",
    "\n",
    "        # reformat context vectors \n",
    "        # (batch, heads, context_len, head_dim) -> (batch, context_len, heads, head_dim)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "        outputs = outputs.contiguous().view(B, T, self.n_heads * self.head_dim)\n",
    "\n",
    "        context_vector = self.proj(outputs)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b7592",
   "metadata": {},
   "source": [
    "#### **Layer Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4e168cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(configs['emb_dim']))\n",
    "        self.shift = nn.Parameter(torch.zeros(configs['emb_dim']))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61f91a",
   "metadata": {},
   "source": [
    "#### **GeLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2f68a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4fc66a",
   "metadata": {},
   "source": [
    "#### **Feed-Forward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8e2ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(configs['emb_dim'], 4*configs['emb_dim']),\n",
    "            GeLU(),\n",
    "            nn.Linear(4*configs['emb_dim'], configs['emb_dim'])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feedforward(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08462379",
   "metadata": {},
   "source": [
    "#### **Transformer Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25c72d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.attn = MultiheadAttention(configs)\n",
    "        self.ff = FeedForward(configs)\n",
    "        self.norm1 = LayerNorm(configs)\n",
    "        self.norm2 = LayerNorm(configs)\n",
    "        self.drop_shortcut = nn.Dropout(configs[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape of x is (B, T, D)\n",
    "        shortcut = x \n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b12f4",
   "metadata": {},
   "source": [
    "#### **GPT-2 Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba660bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        # token embeddings\n",
    "        self.tok_emb = nn.Embedding(configs['vocab_size'], configs['emb_dim'])\n",
    "        # positionl encodings \n",
    "        self.pos_emb = torch.nn.Embedding(configs['context_length'], configs['emb_dim'])\n",
    "        # dropout\n",
    "        self.drop_emb = nn.Dropout(configs['drop_rate'])\n",
    "\n",
    "        # transformer block - encoder only in case of GPT\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(configs) for _ in range(configs['n_layers'])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(configs)\n",
    "        self.out_head = nn.Linear(\n",
    "            configs[\"emb_dim\"], configs[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ade87526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the GPT-2 Model \n",
    "torch.manual_seed(42) # for reproducibility\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "208a7cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size : torch.Size([2, 6])\n",
      "Input tokens : tensor([[33985, 38192, 47025, 29388,  8881, 12568],\n",
      "        [39361,  2038, 22992, 42787, 29012, 30838]])\n",
      "Output shape : torch.Size([2, 6, 50257])\n"
     ]
    }
   ],
   "source": [
    "input_batch = torch.randint(\n",
    "    low=0,\n",
    "    high=GPT_CONFIG_124M[\"vocab_size\"],\n",
    "    size=(2, 6)          # batch=2, seq_len=6 for testing\n",
    ").long()\n",
    "\n",
    "output = model(input_batch)\n",
    "\n",
    "print(f\"Input size : {input_batch.shape}\")\n",
    "print(f\"Input tokens : {input_batch}\")\n",
    "print(f\"Output shape : {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0010946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49714, 46056, 10703, 19770, 34785, 22253],\n",
       "        [12765, 34706, 50092, 36805,   744, 14868]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00ddd844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,037,184\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3f47563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,439,808\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f267996c",
   "metadata": {},
   "source": [
    "As we can see, the model is now only 124 million parameters large, matching the original size of the GPT-2 model.\n",
    "\n",
    "1 KB = 1024 bytes <br>\n",
    "1 MB = 1024 ร 1024 bytes = 1,048,576 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8879e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.94 MB\n"
     ]
    }
   ],
   "source": [
    "## Lastly, let us compute the memory requirements of the 163 million parameters in our GPTModel object:\n",
    "\n",
    "# Each parameter in a PyTorch model (weights, biases) is stored as a 32-bit float (float32) by default.\n",
    "\n",
    "# float32 uses 4 bytes (because: 32 bits รท 8 = 4 bytes)\n",
    "\n",
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ba8bd",
   "metadata": {},
   "source": [
    "#### **Function to predict next token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0e921e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "max_new_tokens = 6\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f9775f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2063, 29761, 27639,  8761]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[27639,  8761]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = torch.randint(0, 50527, (1, 4))\n",
    "print(token_ids)\n",
    "token_ids[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f6897dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(token_ids):\n",
    "    print(token_ids)\n",
    "    context_len = 5\n",
    "    num_iter = 6 \n",
    "    print(f\"Input Sentence : {tokenizer.decode(token_ids.squeeze(dim=0).tolist())}\")\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        if len(token_ids) >= context_len:\n",
    "            input_ids = token_ids[:, -5:]\n",
    "        else:\n",
    "            input_ids = token_ids \n",
    "\n",
    "        model.eval()\n",
    "        outputs = model(input_ids)\n",
    "        # shape of output (B, T, D)\n",
    "        outputs = outputs[:, -1, :]\n",
    "        outputs = torch.softmax(outputs, dim=-1)\n",
    "        outputs = torch.argmax(outputs, dim=-1, keepdim=True)\n",
    "        token_ids = torch.cat((token_ids, outputs), dim=-1)\n",
    "\n",
    "    print(f\"Output Sentences : {tokenizer.decode(token_ids.squeeze(dim=0).tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f555aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33898, 19318, 20158, 40148, 42755]])\n",
      "Input Sentence :  acron octgenerationcodes Macro\n",
      "Output Sentences :  acron octgenerationcodes Macro jourfiction oils Tomato ambul developed\n"
     ]
    }
   ],
   "source": [
    "predict_next_token(torch.randint(0, 50527, (1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebf043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
