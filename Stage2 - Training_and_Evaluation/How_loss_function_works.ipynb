{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0223d5ba",
   "metadata": {},
   "source": [
    "## üîç How Loss Is Calculated While Training Transformers (Step-by-Step)\n",
    "\n",
    "Training a transformer boils down to **comparing predicted token probabilities with the correct target tokens** at every position in the sequence.  \n",
    "Below is a complete walkthrough of how this works mathematically and in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### ### üìå Example Input\n",
    "\n",
    "**Input Tokens (B = 2, T = 4):**\n",
    "\n",
    "[[128, 576, 320, 547],\n",
    "[657, 943, 633, 547]]\n",
    "\n",
    "**Target Tokens (next token for each position):**\n",
    "\n",
    "[[576, 320, 547, 897],\n",
    "[943, 633, 547, 210]]\n",
    "\n",
    "Here:\n",
    "- **B = 2** ‚Üí batch size  \n",
    "- **T = 4** ‚Üí sequence length  \n",
    "- **V = 50,257** ‚Üí vocabulary size for GPT-2  \n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Step 1: Forward Pass ‚Üí Logits\n",
    "\n",
    "When the input goes through the model, the transformer outputs **logits**, not probabilities.\n",
    "\n",
    "**Logits shape:** \n",
    "[Batch_size, Time_steps, Vocabulary_size] = (B, T, V)\n",
    "\n",
    "Each of the 4 positions in each sequence gets a probability distribution over the entire vocab.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßÆ Step 2: Convert Logits ‚Üí Probabilities (Softmax)\n",
    "\n",
    "Softmax is applied along the vocabulary dimension:<br>\n",
    "probs = softmax(logits, dim=-1)<br>\n",
    "This calculates the probabilities of each word fighting for that position\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ Step 3: Reshape (Flatten) Logits and target ids\n",
    "Logits shape : (B, T, V)\n",
    "We convert it to : (B*T, V)\n",
    "\n",
    "new_logits = logits.flatten(start_dim=0, end_dim=1)\n",
    "\n",
    "Traget ids shape : (B, T)\n",
    "New target shape : (B*T)\n",
    "\n",
    "#### Now we have to look for propabilities corresponding to these target ids at each context / time-step\n",
    "\n",
    "-> probabilites of shape (B*T, 1)\n",
    "\n",
    "-> find average of these probs \n",
    "\n",
    "-> take negative log and this is the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347eec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are input tokens to LLM : torch.Size([2, 4])\n",
      "Input tokens : tensor([[11486, 31563,  6140, 17682],\n",
      "        [13134, 22911, 20243, 43382]])\n",
      "Taregt tokens : tensor([[31563,  6140, 17682, 18369],\n",
      "        [22911, 20243, 43382, 45413]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "input_tokens = torch.randint(0, 50257, (2, 4))\n",
    "target_tokens = torch.zeros_like(input_tokens)\n",
    "target_tokens[:, :-1] = input_tokens[:, 1:]\n",
    "target_tokens[:, -1] = torch.randint(0, 50257, (2,))\n",
    "print(f\"These are input tokens to LLM : {input_tokens.shape}\")\n",
    "print(f'Input tokens : {input_tokens}')\n",
    "print(f'Taregt tokens : {target_tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873cd8f9",
   "metadata": {},
   "source": [
    "Now we have input_tokens and target_tokens, we'll send the input tokens to LLM which give output of shape [2, 4, 50257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bdb0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_output = torch.rand((2, 4, 50257))\n",
    "predicted_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74eae1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "# we'll take softmax of the last dim as it represent all words weight for that position \n",
    "import torch.nn.functional as F\n",
    "predicted_output_softmax = F.softmax(predicted_output, dim=-1)\n",
    "print(predicted_output_softmax.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f6bba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether softmax is applied or not \n",
    "predicted_output_softmax[0, 0, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc150af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[17322],\n",
       "         [34935],\n",
       "         [32629],\n",
       "         [18804]],\n",
       "\n",
       "        [[ 2298],\n",
       "         [40166],\n",
       "         [ 7312],\n",
       "         [27669]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token_ids with max_probability are the predicted one\n",
    "predicted_tokens = torch.argmax(predicted_output_softmax, dim=-1, keepdim=True)\n",
    "predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd35422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now for training what we do is we select probabilities corresponding to target_tokens from  predicted tokens \n",
    "target_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5bebc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31563,  6140, 17682, 18369],\n",
       "        [22911, 20243, 43382, 45413]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef59f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = predicted_output_softmax\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3274ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits = logits.flatten(start_dim=0, end_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "624d3db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50257])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fec14fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids = target_tokens.flatten(start_dim=0)\n",
    "target_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c774cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_prob = new_logits.gather(1, target_ids.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fb60fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1652e-05],\n",
       "        [2.0611e-05],\n",
       "        [2.5886e-05],\n",
       "        [2.8628e-05],\n",
       "        [1.3507e-05],\n",
       "        [1.5790e-05],\n",
       "        [2.0037e-05],\n",
       "        [2.1681e-05]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21a0fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9724e-05)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_log_prob = preds_prob.sum()/preds_prob.shape[0]\n",
    "avg_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90a8a2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8337)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = -1*torch.log(avg_log_prob)\n",
    "log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0180a82",
   "metadata": {},
   "source": [
    "This is so called loss that we want to minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1985446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target tokens : torch.Size([2, 4])\n",
      "Shape of predicted output : torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "# now one line of code will do all the things we did above calculating softmax then loss\n",
    "# we have target_tokens and predicted_output\n",
    "print(f\"Shape of target tokens : {target_tokens.shape}\")\n",
    "print(f\"Shape of predicted output : {predicted_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27ba38fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50257])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_output.flatten(start_dim=0, end_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b38ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31563,  6140, 17682, 18369],\n",
       "        [22911, 20243, 43382, 45413]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8c4f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([31563,  6140, 17682, 18369, 22911, 20243, 43382, 45413])\n"
     ]
    }
   ],
   "source": [
    "tks = target_tokens.flatten(start_dim=0)\n",
    "print(tks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8835e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_flatten = predicted_output.reshape(-1, predicted_output.size(-1))  # (B*T, vocab)\n",
    "targets_flatten = target_tokens.reshape(-1)                              # (B*T)\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flatten, targets_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "471b63ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8748)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88db3a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52575.2031)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor(10.87))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b9031",
   "metadata": {},
   "source": [
    "#### **Perplexity Score**\n",
    "\n",
    "More interpretable Perplexity = exponential(loss)\n",
    "\n",
    "Lower preplexity = Better at Prediction\n",
    "\n",
    "Lets say loss = 10.87\n",
    "Perplexity score = 52575 this means model is roughly uncertail as it have to predict next token randomly from 52575 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c594c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
