{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e75275",
   "metadata": {},
   "source": [
    "## üß© Token Embeddings\n",
    "\n",
    "Before a language model can understand or process words,  \n",
    "it needs to **convert them into numbers** ‚Äî because computers operate on numerical data, not text.\n",
    "\n",
    "So, the question is:  \n",
    "> üí≠ *How do we represent words numerically so that the model can understand their meaning?*\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ One-Hot Encoding\n",
    "\n",
    "**Idea:**  \n",
    "Represent each word as a binary vector of size equal to the vocabulary.\n",
    "\n",
    "- Each position corresponds to a word in the vocabulary.  \n",
    "- Only one index (the word‚Äôs position) is set to `1`, and the rest are `0`.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "| Word | One-Hot Vector |\n",
    "|------|----------------|\n",
    "| dog | [0, 0, 0, 1, 0, 0, 0, 0] |\n",
    "| cat | [0, 0, 1, 0, 0, 0, 0, 0] |\n",
    "\n",
    "**Drawbacks:**\n",
    "- ‚ö†Ô∏è **Sparse representation:** Mostly zeros ‚Üí memory inefficient  \n",
    "- ‚ö†Ô∏è **No semantic meaning:**  \n",
    "  ‚Äúdog‚Äù and ‚Äúpuppy‚Äù are very similar in reality,  \n",
    "  but their one-hot vectors are completely different.\n",
    "\n",
    "> üìâ Example:  \n",
    "> `'dog'` at index **5** and `'puppy'` at index **127** show no similarity numerically,  \n",
    "> even though they mean almost the same thing.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Embeddings (Dense Vector Representations)\n",
    "\n",
    "**Idea:**  \n",
    "Instead of one-hot encoding, represent each token as a **dense, low-dimensional vector**  \n",
    "that captures its **semantic meaning** ‚Äî relationships and similarities between words.\n",
    "\n",
    "Each word becomes a vector like:<br>\n",
    "dog ‚Üí [0.62, 0.13, 0.55, 0.02, 0.44, ...]<br>\n",
    "puppy ‚Üí [0.60, 0.10, 0.50, 0.05, 0.47, ...]\n",
    "\n",
    "\n",
    "Here, `\"dog\"` and `\"puppy\"` have **similar vectors**,  \n",
    "so their **cosine similarity** is high ‚Äî meaning the model understands their relatedness.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Why Embeddings Work\n",
    "\n",
    "- They capture **semantic relationships** between words (e.g., `\"king\" - \"man\" + \"woman\" ‚âà \"queen\"`).\n",
    "- They allow the model to **generalize** and understand new combinations of words.\n",
    "- They make computations efficient since vectors are **dense** and **low-dimensional**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è How Embeddings Are Learned\n",
    "\n",
    "Embeddings are not hand-coded ‚Äî they‚Äôre **learned automatically** during training using neural networks such as:\n",
    "- **CBOW (Continuous Bag of Words)**  \n",
    "  ‚Üí Predicts a target word from its surrounding context.\n",
    "- **Skip-Gram**  \n",
    "  ‚Üí Predicts surrounding words from a target word.\n",
    "\n",
    "These models are the foundation of **Word2Vec**, and modern LLMs extend the same concept for tokens.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ú® In Summary\n",
    "\n",
    "| Concept | Representation | Pros | Cons |\n",
    "|----------|----------------|------|------|\n",
    "| **One-Hot Encoding** | Sparse binary vector | Simple, easy | High-dimensional, no meaning |\n",
    "| **Embeddings** | Dense numeric vector | Captures meaning, efficient | Requires training |\n",
    "\n",
    "---\n",
    "\n",
    "> üß© **Bottom line:**  \n",
    "> Embeddings turn words into *meaningful numbers* ‚Äî  \n",
    "> enabling models like GPT to understand and generate human language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23cf692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim (a popular Python library for word embeddings, topic modeling, and NLP tasks)\n",
    "import gensim.downloader as api \n",
    "model = api.load('word2vec-google-news-300')\n",
    "word_vectors = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1185e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding vector : 300\n",
      "Embedding : [ 0.32421875 -0.24316406  0.11523438  0.25976562 -0.18847656  0.10595703\n",
      " -0.10205078  0.10693359  0.28710938  0.01428223  0.0100708  -0.20214844\n",
      "  0.19238281  0.07714844 -0.03686523  0.06933594 -0.0013504   0.26757812\n",
      "  0.12011719  0.02746582 -0.0072937  -0.04443359  0.15625     0.10693359\n",
      "  0.1640625  -0.07177734  0.02355957 -0.03930664 -0.05004883 -0.17480469\n",
      " -0.06054688 -0.10839844 -0.17382812  0.01843262  0.14160156 -0.4140625\n",
      " -0.43554688 -0.12792969  0.1484375  -0.04882812 -0.11914062  0.23046875\n",
      "  0.265625    0.10400391  0.27929688  0.06933594 -0.03881836  0.31640625\n",
      " -0.40625     0.05712891 -0.01324463 -0.09960938  0.05737305 -0.18945312\n",
      " -0.15039062  0.23632812 -0.05102539 -0.17871094 -0.21972656  0.14746094\n",
      "  0.16308594  0.04736328 -0.13183594  0.22070312 -0.04003906  0.05517578\n",
      " -0.2734375   0.42773438 -0.25585938  0.06591797  0.05419922 -0.25\n",
      "  0.14453125 -0.00531006 -0.08984375 -0.01312256  0.08349609 -0.203125\n",
      " -0.0022583  -0.25390625  0.08935547  0.08447266  0.27539062  0.2890625\n",
      "  0.00595093 -0.15625     0.00994873  0.29882812 -0.04980469  0.11523438\n",
      "  0.11914062 -0.04052734 -0.05737305 -0.33203125  0.19238281 -0.18359375\n",
      "  0.11132812  0.20410156  0.21582031  0.10302734  0.2734375  -0.23535156\n",
      " -0.09912109  0.16699219  0.09619141  0.17871094 -0.14453125 -0.09472656\n",
      "  0.44140625  0.00062561 -0.11083984 -0.18945312 -0.09912109 -0.01361084\n",
      "  0.10449219  0.12451172 -0.00805664 -0.00817871  0.07861328  0.02722168\n",
      " -0.31445312  0.14160156 -0.11523438 -0.01281738 -0.13085938  0.06787109\n",
      " -0.18847656 -0.01525879  0.00552368  0.16601562  0.12890625 -0.3515625\n",
      "  0.02490234  0.16894531  0.09667969  0.13671875  0.07958984 -0.09228516\n",
      " -0.55859375 -0.25       -0.04248047 -0.27539062  0.14355469  0.02197266\n",
      "  0.05200195  0.01373291  0.2890625  -0.11083984 -0.21582031 -0.07958984\n",
      "  0.11816406  0.02807617 -0.14453125  0.19921875 -0.13085938  0.22265625\n",
      " -0.25       -0.00714111 -0.22753906  0.01940918 -0.06689453  0.05297852\n",
      " -0.11474609 -0.06933594  0.09521484  0.14160156 -0.11230469 -0.046875\n",
      " -0.22753906 -0.01574707 -0.08105469  0.09375    -0.15234375  0.11865234\n",
      " -0.04345703 -0.04760742 -0.05883789 -0.15136719 -0.234375   -0.10107422\n",
      " -0.04833984 -0.24121094 -0.07568359 -0.27539062  0.21582031  0.03710938\n",
      " -0.12304688  0.06445312  0.20996094 -0.07177734 -0.04003906 -0.01879883\n",
      " -0.16015625  0.20703125  0.03027344  0.25390625  0.15722656 -0.32617188\n",
      " -0.08300781 -0.05273438 -0.05102539  0.01324463  0.23925781  0.22558594\n",
      "  0.26171875 -0.03271484  0.10839844 -0.18652344 -0.33007812 -0.2421875\n",
      " -0.00081253  0.10400391 -0.16015625  0.04296875  0.17089844  0.25585938\n",
      " -0.13085938  0.37304688 -0.453125   -0.18945312 -0.09326172 -0.234375\n",
      "  0.07470703  0.22949219 -0.17578125 -0.07763672 -0.33789062  0.03955078\n",
      " -0.140625   -0.3046875  -0.09228516 -0.14648438 -0.07177734 -0.30273438\n",
      " -0.15625    -0.17578125  0.06542969 -0.14746094  0.09912109  0.14355469\n",
      "  0.20703125  0.05639648 -0.10058594 -0.03198242 -0.10693359 -0.03515625\n",
      " -0.11523438  0.09375     0.06689453 -0.01544189 -0.328125    0.25\n",
      " -0.23242188  0.078125   -0.11328125 -0.15136719  0.07519531  0.00762939\n",
      " -0.09033203  0.05249023 -0.02050781 -0.05151367  0.01831055  0.09033203\n",
      "  0.05761719  0.11669922 -0.13769531  0.19335938 -0.04370117  0.359375\n",
      " -0.08398438 -0.03417969  0.00369263  0.1484375   0.08105469 -0.15917969\n",
      "  0.18554688 -0.28515625  0.15917969  0.05615234 -0.07519531  0.10205078\n",
      " -0.01745605  0.125       0.10693359 -0.1484375   0.23535156  0.18261719\n",
      "  0.10546875  0.29492188 -0.35351562  0.01745605  0.03442383 -0.26171875\n",
      "  0.06176758 -0.23242188  0.01696777 -0.00604248 -0.02856445 -0.07275391]\n"
     ]
    }
   ],
   "source": [
    "# lets look at embedding of word 'computers'\n",
    "embed = word_vectors['computers']\n",
    "print(f\"Length of embedding vector : {embed.shape[0]}\")\n",
    "print(f\"Embedding : {embed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683e0a3",
   "metadata": {},
   "source": [
    "What are similar to KING + WOMEN - MAN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550bf34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.4827326238155365),\n",
       " ('queens', 0.466781347990036),\n",
       " ('kumaris', 0.4653734564781189),\n",
       " ('kings', 0.4558638036251068),\n",
       " ('womens', 0.422832190990448),\n",
       " ('princes', 0.4176960587501526),\n",
       " ('Al_Anqari', 0.41725507378578186),\n",
       " ('concubines', 0.4011078476905823),\n",
       " ('monarch', 0.39624831080436707),\n",
       " ('monarchy', 0.39430150389671326)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['king', 'women'], negative=['man'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9c855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('girl', 0.8543271422386169),\n",
       " ('teenager', 0.7606689929962158),\n",
       " ('toddler', 0.7043969035148621),\n",
       " ('teenage_girl', 0.685148298740387),\n",
       " ('man', 0.6824870109558105),\n",
       " ('teen_ager', 0.6499968767166138),\n",
       " ('son', 0.6337764263153076),\n",
       " ('kid', 0.63228440284729),\n",
       " ('youngster', 0.618381679058075),\n",
       " ('stepfather', 0.5989423394203186)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some similar words to 'boy' \n",
    "word_vectors.most_similar('boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5088cb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n",
      "0.6510956\n",
      "0.76434743\n",
      "0.8543272\n",
      "0.7594367\n",
      "0.11408083\n"
     ]
    }
   ],
   "source": [
    "# Example of calculating similarity\n",
    "print(word_vectors.similarity('woman', 'man'))\n",
    "print(word_vectors.similarity('king', 'queen'))\n",
    "print(word_vectors.similarity('uncle', 'aunt'))\n",
    "print(word_vectors.similarity('boy', 'girl'))\n",
    "print(word_vectors.similarity('nephew', 'niece'))\n",
    "print(word_vectors.similarity('paper', 'water'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f663b3",
   "metadata": {},
   "source": [
    "#### Magnitude of difference between word vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56495c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of the difference between 'man' and 'woman' is 1.73\n",
      "The magnitude of the difference between 'semiconductor' and 'earthworm' is 5.67\n",
      "The magnitude of the difference between 'nephew' and 'niece' is 1.96\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Words to compare\n",
    "word1 = 'man'\n",
    "word2 = 'woman'\n",
    "\n",
    "word3 = 'semiconductor'\n",
    "word4 = 'earthworm'\n",
    "\n",
    "word5 = 'nephew'\n",
    "word6 = 'niece'\n",
    "\n",
    "# Calculate the vector difference\n",
    "vector_difference1 = model[word1] - model[word2]\n",
    "vector_difference2 = model[word3] - model[word4]\n",
    "vector_difference3 = model[word5] - model[word6]\n",
    "\n",
    "# Calculate the magnitude of the vector difference (L2 norm of vectors (sum=x^2)^(1/2))\n",
    "magnitude_of_difference1 = np.linalg.norm(vector_difference1)\n",
    "magnitude_of_difference2 = np.linalg.norm(vector_difference2)\n",
    "magnitude_of_difference3 = np.linalg.norm(vector_difference3)\n",
    "\n",
    "\n",
    "# Print the magnitude of the difference\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word1, word2, magnitude_of_difference1))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word3, word4, magnitude_of_difference2))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word5, word6, magnitude_of_difference3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252de589",
   "metadata": {},
   "source": [
    "### How token embeddings are trained or created for LLMs?\n",
    "\n",
    "1) Token embeddings for a model are learned while training LLM itself\n",
    "2) Take a matrix of V X N, where V = size of vocabulary and N = dimension of embeddings\n",
    "    Initialize the weights randomly, and let it learn while training LLM for predicting next token\n",
    "\n",
    "Sentence -> Token IDs -> look at the matrix to find word embedding corresponding to particular ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d87ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a short example\n",
    "import torch\n",
    "# lets suppose we have a vocabulary of size 6, and we have a random sentence with these token ids \n",
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f9160b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(6, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "embd_dim = 3 \n",
    "\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, embd_dim)\n",
    "embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70ec5279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of embedding layer : Parameter containing:\n",
      "tensor([[ 0.1464,  1.1386, -0.7314],\n",
      "        [-0.7409, -0.8005, -0.2101],\n",
      "        [ 0.3874,  0.3309,  0.6376],\n",
      "        [-0.0957, -1.4444,  0.5150],\n",
      "        [-0.2883, -1.9432,  0.2287],\n",
      "        [ 0.5217,  0.5607, -0.6591]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# lets look at weights of this embedding layer \n",
    "print(f\"Weights of embedding layer : {embedding_layer.weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23544c3d",
   "metadata": {},
   "source": [
    "While training LLM these weights gets also updated and makes embeddings for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee90c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding corresponding to index 3 : tensor([[-0.0957, -1.4444,  0.5150]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# accessing vector embedding corresponding to a particular index \n",
    "embed_vector = embedding_layer(torch.tensor([3]))\n",
    "print(f\"Embedding corresponding to index 3 : {embed_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e270cd",
   "metadata": {},
   "source": [
    "Converting input_ids vector to embedding vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3874,  0.3309,  0.6376],\n",
       "        [-0.0957, -1.4444,  0.5150],\n",
       "        [ 0.5217,  0.5607, -0.6591],\n",
       "        [-0.7409, -0.8005, -0.2101]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedding_layer(input_ids)\n",
    "# input_ids = torch.tensor([2, 3, 5, 1])\n",
    "# it will look for vector corresponding to these ids-1\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc77ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
